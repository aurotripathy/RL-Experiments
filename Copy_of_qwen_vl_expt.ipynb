{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMy49YumL6M+Mhf8yoo1022",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aurotripathy/RL-Experiments/blob/main/Copy_of_qwen_vl_expt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Ensure you change the runtime to A100 - 80GB"
      ],
      "metadata": {
        "id": "fnYzToaYe67I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "%pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "I8RHPEf3fK7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "K6M3MTjPfgzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jason_schema = {\n",
        "  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "  \"title\": \"NutritionFacts\",\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"product_name\": { \"type\": [\"string\", \"null\"] },\n",
        "    \"brand\": { \"type\": [\"string\", \"null\"] },\n",
        "    \"source_url\": { \"type\": \"string\", \"format\": \"uri\" },\n",
        "    \"servings_per_container\": { \"type\": [\"number\", \"string\", \"null\"] },\n",
        "    \"serving_size\": {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        \"quantity\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"unit\": { \"type\": [\"string\", \"null\"] },\n",
        "        \"description\": { \"type\": [\"string\", \"null\"] }\n",
        "      },\n",
        "      \"required\": [\"quantity\", \"unit\"]\n",
        "    },\n",
        "    \"calories\": { \"type\": [\"number\", \"null\"] },\n",
        "    \"macros\": {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        \"total_fat_g\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"total_fat_dv_percent\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"saturated_fat_g\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"saturated_fat_dv_percent\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"trans_fat_g\": { \"type\": [\"number\", \"null\", \"string\"] },\n",
        "        \"cholesterol_mg\": { \"type\": [\"number\", \"null\", \"string\"] },\n",
        "        \"cholesterol_dv_percent\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"sodium_mg\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"sodium_dv_percent\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"total_carbohydrate_g\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"total_carbohydrate_dv_percent\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"dietary_fiber_g\": { \"type\": [\"number\", \"null\", \"string\"] },\n",
        "        \"dietary_fiber_dv_percent\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"total_sugars_g\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"added_sugars_g\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"added_sugars_dv_percent\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"protein_g\": { \"type\": [\"number\", \"null\"] }\n",
        "      },\n",
        "      \"required\": [\"total_fat_g\",\"saturated_fat_g\",\"trans_fat_g\",\"sodium_mg\",\"total_carbohydrate_g\",\"protein_g\"]\n",
        "    },\n",
        "    \"micronutrients_dv_percent\": {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        \"vitamin_d\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"calcium\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"iron\": { \"type\": [\"number\", \"null\"] },\n",
        "        \"potassium\": { \"type\": [\"number\", \"null\"] }\n",
        "      }\n",
        "    },\n",
        "    \"notes\": { \"type\": [\"string\", \"null\"] }\n",
        "  },\n",
        "  \"required\": [\"source_url\", \"serving_size\", \"macros\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "lkR7ZjtSRvbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import Qwen3VLMoeForConditionalGeneration, AutoProcessor\n",
        "import torch\n",
        "\n",
        "model_name = \"Qwen/Qwen3-VL-30B-A3B-Instruct\"\n",
        "\n",
        "# default: Load the model on the available device(s)\n",
        "# model = Qwen3VLMoeForConditionalGeneration.from_pretrained(\n",
        "#     model_name, dtype=\"auto\", device_map=\"cuda\"\n",
        "# )\n",
        "\n",
        "\n",
        "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
        "model = Qwen3VLMoeForConditionalGeneration.from_pretrained(\n",
        "    model_name,\n",
        "    dtype=torch.bfloat16,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    device_map=\"cuda\",\n",
        ")"
      ],
      "metadata": {
        "id": "6XBAQ_ZGT5uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "instruction = f\"Extract all the nutrition information in JSON format according to the following schema:\\n{json.dumps(jason_schema, indent=2)}\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen3-VL-30B-A3B-Instruct\")\n",
        "\n",
        "# image_link = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\n",
        "image_link = \"https://s7d1.scene7.com/is/image/hersheyprodcloud/0_34000_00246_7_701_24600_073_Item_Back_B?fmt=webp-alpha&hei=908&qlt=75\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"image\": image_link,\n",
        "            },\n",
        "            {\"type\": \"text\", \"text\": instruction},\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "# Preparation for inference with the updated messages\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Inference: Generation of the output\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=1024) # Increased max_new_tokens\n",
        "generated_ids_trimmed = [\n",
        "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "]\n",
        "output_text = processor.batch_decode(\n",
        "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        ")\n",
        "print(output_text[0]) # Print the first output"
      ],
      "metadata": {
        "id": "9V0i_uWER8sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1089e14"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "import requests\n",
        "\n",
        "# Assuming the image is the first item in the first message's content\n",
        "image_url = messages[0]['content'][0]['image']\n",
        "\n",
        "# Download the image from the URL\n",
        "response = requests.get(image_url)\n",
        "with open(\"temp_image.jpeg\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Display the image\n",
        "display(Image(filename=\"temp_image.jpeg\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}